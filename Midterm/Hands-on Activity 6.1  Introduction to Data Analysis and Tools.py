# -*- coding: utf-8 -*-
"""Esperat - Hands-on Activity 6.1 | Introduction to Data Analysis and Tools

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_4RH9B0bZ3spBYIos0tqXX0-DJmPKqIt

# Hands-on Activity 6.1 Introduction to Data Analysis and Tools

CPE311 Computational Thinking with Python

Name: Esperat, Gwyneth

Section: CPE22S3

Performed on: 03/07/2024

Submitted on: 03/07/2024

Submitted to: Engr. Roman M. Richard

# 6.1 Intended Learning Outcome

1. Use pandas and numpy data analysis tools.
2. Demonstrate how to analyze data using numpy and pandas

# 6.2 Resources:
* Personal Computer
* Jupyter Notebook
* Internet Connection

# 6.3 Supplementary Activities:

# Exercise 1
Run the given code below for exercises 1 and 2, perform the given tasks without using any Python modules.

Using the data generated above, calculate the following statistics without importing anything from the statistics module in the
standard library (https://docs.python.org/3/library/statistics.html) and then confirm your results match up to those that are
obtained when using the statistics module (where possible):
* Mean
* Median
* Mode (hint: check out the Counter in the collections module of the standard library at
https://docs.python.org/3/library/collections.html#collections.Counter)
* Sample variance
* Sample standard deviation
"""

import random
random.seed(0)
salaries = [round(random.random() * 1000000 - 3) for _ in range(100)]

# Mean
mean_salary = sum(salaries) / len(salaries)

# Median
sorted_salaries = sorted(salaries)
if len(sorted_salaries) % 2 == 0:
    median_salary = (sorted_salaries[len(sorted_salaries) // 2 - 1] + sorted_salaries[len(sorted_salaries) // 2]) / 2
else:
    median_salary = sorted_salaries[len(sorted_salaries) // 2]

# Mode
from collections import Counter
mode_data = Counter(salaries)
mode_salary = mode_data.most_common(1)[0][0]

# Sample variance
variance_salary = sum((x - mean_salary) ** 2 for x in salaries) / (len(salaries) - 1)

# Sample standard deviation
std_dev_salary = variance_salary ** 0.5

(mean_salary, median_salary, mode_salary, variance_salary, std_dev_salary)

"""# Exercise 2

Using the same data, calculate the following statistics using the functions in the statistics module where appropriate:
* Range
* Coefficient of variation Interquartile range
* Quartile coefficient of dispersion
"""

from statistics import mean, median, mode, variance, stdev
from scipy.stats import iqr

# Calculate salary range
salary_range = max(salaries) - min(salaries)

# Calculate coefficient of variation
coef_of_variation = stdev(salaries) / mean(salaries)

# Calculate interquartile range
q1 = np.percentile(salaries, 25)
q3 = np.percentile(salaries, 75)
interquartile_range = q3 - q1

# Calculate quartile coefficient of dispersion
qcd = interquartile_range / ((q1 + q3) / 2) if q1 and q3 else 0

(salary_range, coef_of_variation, interquartile_range, qcd)

"""# Exercise 3: Pandas for Data Analysis

Load the diabetes.csv file. Convert the diabetes.csv into dataframe

Perform the following tasks in the diabetes dataframe:

1. Identify the column names
2. Identify the data types of the data
3. Display the total number of records
4. Display the first 20 records
5. Display the last 20 records
6. Change the Outcome column to Diagnosis
7. Create a new column Classification that display "Diabetes" if the value of outcome is 1 , otherwise "No Diabetes"
8. Create a new dataframe "withDiabetes" that gathers data with diabetes
9. Create a new dataframe "noDiabetes" thats gathers data with no diabetes
10. Create a new dataframe "Pedia" that gathers data with age 0 to 19
11. Create a new dataframe "Adult" that gathers data with age greater than 19
12. Use numpy to get the average age and glucose value.
13. Use numpy to get the median age and glucose value.
14. Use numpy to get the middle values of glucose and age.
15. Use numpy to get the standard deviation of the skinthickness.


"""

import pandas as pd
import numpy as np

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Ensure this path corresponds to the actual location of 'diabetes.csv' in your Google Drive
file_path = '/content/drive/MyDrive/diabetes.csv'

# Try to read the file
try:
    df = pd.read_csv(file_path)
    print(df.head())  # Display the first few rows to confirm it's loaded correctly
except FileNotFoundError:
    print(f"File not found. Make sure the filepath is correct: {file_path}")

# Identify the column names
column_names = df.columns.tolist()

# Data types
data_types = df.dtypes

# Total number of records
total_records = len(df)

# First 20 records
first_20_records = df.head(20)

# Last 20 records
last_20_records = df.tail(20)

# Change the 'Outcome' column to 'Diagnosis'
df.rename(columns={'Outcome': 'Diagnosis'}, inplace=True)

# Create a new column 'Classification'
df['Classification'] = np.where(df['Diagnosis'] == 1, 'Diabetes', 'No Diabetes')

# DataFrames based on condition
withDiabetes = df[df['Diagnosis'] == 1]
noDiabetes = df[df['Diagnosis'] == 0]
Pedia = df[df['Age'] <= 19]
Adult = df[df['Age'] > 19]

# Numpy statistical calculations
average_age = np.mean(df['Age'])
average_glucose = np.mean(df['Glucose'])
median_age = np.median(df['Age'])
median_glucose = np.median(df['Glucose'])
middle_values = np.median(df[['Age', 'Glucose']], axis=0)
std_dev_skinthickness = np.std(df['SkinThickness'])

# Output results
results = {
    'Column Names': column_names,
    'Data Types': data_types,
    'Total Records': total_records,
    'First 20 Records': first_20_records,
    'Last 20 Records': last_20_records,
    'With Diabetes': withDiabetes.head(),
    'Without Diabetes': noDiabetes.head(),
    'Pediatric Patients': Pedia.head(),
    'Adult Patients': Adult.head(),
    'Average Age': average_age,
    'Average Glucose': average_glucose,
    'Median Age': median_age,
    'Median Glucose': median_glucose,
    'Middle Values': middle_values,
    'Standard Deviation of Skin Thickness': std_dev_skinthickness
}

results

"""# 6.4 Conclusion

In this activity explored practical data analysis using Python, Pandas, and NumPy, focusing on diabetes data. They practiced manual statistical calculations to grasp fundamental concepts before transitioning to Python's built-in functions for efficiency. The core component involved using Pandas for data manipulation and NumPy for analysis, reinforcing skills applicable in data science. This hands-on approach emphasized the importance of understanding and applying various data analysis tools, essential for entry into the field or enhancing analytical capabilities in the digital age.
"""